{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9092f3a1-4f0b-4f24-9d72-663c5c0362f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1a: User-based predictions\n",
      "Taylor's Bondswoman’s Narrative: 4.0\n",
      "Ainsley's Northanger Abby: 2.3333333333333335\n",
      "\n",
      "Question 1b: Item-based predictions\n",
      "Taylor's Bondswoman’s Narrative: -0.753552340806314\n",
      "Ainsley's Northanger Abby: -0.1721605090644537\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Utility matrix\n",
    "data = {\n",
    "    'Northanger Abby': [5, 1, 1, None],\n",
    "    'Wuthering Heights': [4, 2, 2, 4],\n",
    "    'Oroonoko': [3, 4, 3, 3],\n",
    "    \"Bondswoman’s Narrative\": [4, 5, None, 1]\n",
    "}\n",
    "users = ['Alex', 'Loren', 'Taylor', 'Ainsley']\n",
    "df = pd.DataFrame(data, index=users)\n",
    "\n",
    "# Helper functions\n",
    "def user_mean_centered_ratings(user):\n",
    "    return df.loc[user] - df.loc[user].mean(skipna=True)\n",
    "\n",
    "def pearson_sim(user1, user2):\n",
    "    common_ratings = df.loc[[user1, user2]].dropna(axis=1)\n",
    "    if len(common_ratings.columns) < 2:\n",
    "        return 0\n",
    "    return pearsonr(common_ratings.loc[user1], common_ratings.loc[user2])[0]\n",
    "\n",
    "# (a) User-based collaborative filtering with Pearson and mean-centering\n",
    "def predict_user_based(target_user, target_item):\n",
    "    # Compute similarities with other users\n",
    "    similarities = {}\n",
    "    for user in users:\n",
    "        if user != target_user and not pd.isna(df.loc[user, target_item]):\n",
    "            sim = pearson_sim(target_user, user)\n",
    "            similarities[user] = sim\n",
    "    \n",
    "    # Select users with positive similarity\n",
    "    similarities = {k:v for k,v in similarities.items() if v > 0}\n",
    "    if not similarities:\n",
    "        return df[target_item].mean()  # Fallback to global mean\n",
    "    \n",
    "    # Calculate weighted sum of mean-centered ratings\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    target_mean = df.loc[target_user].mean(skipna=True)\n",
    "    for user, sim in similarities.items():\n",
    "        user_mean = df.loc[user].mean(skipna=True)\n",
    "        rating = df.loc[user, target_item]\n",
    "        numerator += sim * (rating - user_mean)\n",
    "        denominator += abs(sim)\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return target_mean\n",
    "    return target_mean + (numerator / denominator)\n",
    "\n",
    "# (b) Item-based collaborative filtering with adjusted cosine similarity\n",
    "def adjusted_cosine(item1, item2):\n",
    "    # Subtract user mean for each rating\n",
    "    common_users = df[[item1, item2]].dropna().index\n",
    "    if len(common_users) == 0:\n",
    "        return 0\n",
    "    adjusted_ratings = []\n",
    "    for user in common_users:\n",
    "        user_mean = df.loc[user].mean(skipna=True)\n",
    "        adj1 = df.loc[user, item1] - user_mean\n",
    "        adj2 = df.loc[user, item2] - user_mean\n",
    "        adjusted_ratings.append((adj1, adj2))\n",
    "    a = np.array([x[0] for x in adjusted_ratings])\n",
    "    b = np.array([x[1] for x in adjusted_ratings])\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n",
    "\n",
    "def predict_item_based(target_user, target_item):\n",
    "    # Find similar items\n",
    "    similarities = {}\n",
    "    for item in df.columns:\n",
    "        if item != target_item and not pd.isna(df.loc[target_user, item]):\n",
    "            sim = adjusted_cosine(target_item, item)\n",
    "            similarities[item] = sim\n",
    "    \n",
    "    # Calculate weighted average\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for item, sim in similarities.items():\n",
    "        rating = df.loc[target_user, item]\n",
    "        numerator += sim * rating\n",
    "        denominator += abs(sim)\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return df[target_item].mean()\n",
    "    return numerator / denominator\n",
    "\n",
    "# Predict missing values\n",
    "print(\"Question 1a: User-based predictions\")\n",
    "print(\"Taylor's Bondswoman’s Narrative:\", predict_user_based('Taylor', \"Bondswoman’s Narrative\"))\n",
    "print(\"Ainsley's Northanger Abby:\", predict_user_based('Ainsley', 'Northanger Abby'))\n",
    "\n",
    "print(\"\\nQuestion 1b: Item-based predictions\")\n",
    "print(\"Taylor's Bondswoman’s Narrative:\", predict_item_based('Taylor', \"Bondswoman’s Narrative\"))\n",
    "print(\"Ainsley's Northanger Abby:\", predict_item_based('Ainsley', 'Northanger Abby'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a02942b9-01a9-497f-9507-d86a3dcbc132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 2b: Unique series: ['Apharan', 'Criminal Justice', 'Mirzapur', 'Panchayat', 'Sacred Games', 'Special Ops']\n",
      "\n",
      "Question 2e/g: Recommendations for Ritvik: ['Criminal Justice', 'Apharan', 'Special Ops']\n"
     ]
    }
   ],
   "source": [
    "# (a) Sample dictionary\n",
    "dataset = {\n",
    "    'Rahul': {'Special Ops': 5, 'Criminal Justice': 3, 'Panchayat': 3, 'Sacred Games': 3, 'Apharan': 2, 'Mirzapur': 3},\n",
    "    'Rishabh': {'Special Ops': 5, 'Criminal Justice': 3, 'Sacred Games': 5, 'Panchayat': 5, 'Mirzapur': 3, 'Apharan': 3},\n",
    "    'Sonali': {'Special Ops': 2, 'Panchayat': 5, 'Sacred Games': 3, 'Mirzapur': 4},\n",
    "    'Ritvik': {'Panchayat': 5, 'Mirzapur': 4, 'Sacred Games': 4},\n",
    "    'Harshita': {'Special Ops': 4, 'Criminal Justice': 4, 'Panchayat': 4, 'Mirzapur': 3, 'Apharan': 2},\n",
    "    'Shubhi': {'Special Ops': 3, 'Panchayat': 4, 'Mirzapur': 3, 'Sacred Games': 5, 'Apharan': 3},\n",
    "    'Shaurya': {'Panchayat': 4, 'Apharan': 1, 'Sacred Games': 4}\n",
    "}\n",
    "\n",
    "# (b) Unique web series\n",
    "def unique_series(data):\n",
    "    series = set()\n",
    "    for user in data.values():\n",
    "        series.update(user.keys())\n",
    "    return sorted(series)\n",
    "print(\"\\nQuestion 2b: Unique series:\", unique_series(dataset))\n",
    "\n",
    "# (c) Cosine similarity between two items\n",
    "def cosine_sim(item1, item2, data):\n",
    "    # Collect ratings for users who rated both items\n",
    "    common_users = []\n",
    "    for user, ratings in data.items():\n",
    "        if item1 in ratings and item2 in ratings:\n",
    "            common_users.append((ratings[item1], ratings[item2]))\n",
    "    if not common_users:\n",
    "        return 0\n",
    "    a = np.array([x[0] for x in common_users])\n",
    "    b = np.array([x[1] for x in common_users])\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)\n",
    "\n",
    "# (d) Similarity between target and others\n",
    "def item_similarities(target_item, data):\n",
    "    items = unique_series(data)\n",
    "    similarities = {}\n",
    "    for item in items:\n",
    "        if item != target_item:\n",
    "            similarities[item] = cosine_sim(target_item, item, data)\n",
    "    return similarities\n",
    "\n",
    "# (f) Seen and unseen series\n",
    "def seen_unseen(user, data):\n",
    "    seen = set(data[user].keys())\n",
    "    all_series = unique_series(data)\n",
    "    unseen = [s for s in all_series if s not in seen]\n",
    "    return seen, unseen\n",
    "\n",
    "# (e & g) Recommender function\n",
    "def recommend(user, data, top_n=3):\n",
    "    seen, unseen = seen_unseen(user, data)\n",
    "    item_scores = {}\n",
    "    for seen_item in seen:\n",
    "        sims = item_similarities(seen_item, data)\n",
    "        for unseen_item, sim in sims.items():\n",
    "            if unseen_item in unseen:\n",
    "                if unseen_item not in item_scores:\n",
    "                    item_scores[unseen_item] = 0\n",
    "                item_scores[unseen_item] += sim * data[user][seen_item]\n",
    "    # Sort by score\n",
    "    sorted_items = sorted(item_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [item[0] for item in sorted_items[:top_n]]\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nQuestion 2e/g: Recommendations for Ritvik:\", recommend('Ritvik', dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c22f9c-dcdd-4b3c-9d80-b81939fb5d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 3b SVD Predictions:\n",
      " [[4.83112638 3.10573185 4.14043801 0.89496859]\n",
      " [4.0222121  2.63300547 3.716315   1.15259687]\n",
      " [0.92159828 1.15258946 3.97766205 4.99704519]\n",
      " [3.5578411  2.4781175  4.1357998  2.30420504]]\n",
      "\n",
      "Question 3c PCA Predictions:\n",
      " [[ 2.32008098  0.04686596 -0.88138367 -1.22292937]\n",
      " [ 1.71700535 -0.29886649 -1.14306647 -0.1795867 ]\n",
      " [-1.55063606 -1.08860774 -0.96661685  3.11689966]\n",
      " [-2.48645026  1.34060827  2.99106698 -1.71438359]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "data = np.array([[5, 3, 0, 1], [4, 0, 0, 1], [1, 1, 0, 5], [0, 3, 4, 0]])\n",
    "\n",
    "# (a) Matrix factorization (using SVD as approximation)\n",
    "def matrix_factorization_prediction(data, rank=2):\n",
    "    # Impute missing values (assuming 0 is missing)\n",
    "    imputer = SimpleImputer(missing_values=0, strategy='mean')\n",
    "    data_imputed = imputer.fit_transform(data)\n",
    "    # Perform SVD\n",
    "    U, sigma, Vt = np.linalg.svd(data_imputed, full_matrices=False)\n",
    "    # Reconstruct matrix\n",
    "    reconstructed = U[:, :rank] @ np.diag(sigma[:rank]) @ Vt[:rank, :]\n",
    "    return reconstructed\n",
    "\n",
    "# (b) SVD prediction\n",
    "svd_reconstructed = matrix_factorization_prediction(data)\n",
    "print(\"\\nQuestion 3b SVD Predictions:\\n\", svd_reconstructed)\n",
    "\n",
    "# (c) PCA prediction\n",
    "def pca_prediction(data, n_components=2):\n",
    "    # Center data\n",
    "    data_centered = data - np.mean(data, axis=0)\n",
    "    # Impute missing (0s)\n",
    "    imputer = SimpleImputer(missing_values=0, strategy='mean')\n",
    "    data_imputed = imputer.fit_transform(data_centered)\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced = pca.fit_transform(data_imputed)\n",
    "    reconstructed = pca.inverse_transform(reduced)\n",
    "    return reconstructed\n",
    "\n",
    "pca_reconstructed = pca_prediction(data)\n",
    "print(\"\\nQuestion 3c PCA Predictions:\\n\", pca_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d556ca-2d31-440b-9c61-02848779ae4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
