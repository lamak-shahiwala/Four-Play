{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c043fae8-2f25-4303-9082-68b9870fb0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cosine functions:  [[1.         0.96976515 0.79802388 0.8304548 ]\n",
      " [0.96976515 1.         0.84883822 0.91914503]\n",
      " [0.79802388 0.84883822 1.         0.96396037]\n",
      " [0.8304548  0.91914503 0.96396037 1.        ]]\n",
      "pcc_similarity user      user1     user2     user3     user4\n",
      "user                                         \n",
      "user1  1.000000  0.654654 -0.785714 -0.981981\n",
      "user2  0.654654  1.000000 -0.981981 -0.500000\n",
      "user3 -0.785714 -0.981981  1.000000  0.654654\n",
      "user4 -0.981981 -0.500000  0.654654  1.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "data={\n",
    "    'user':['user1','user2','user3','user4'],\n",
    "    'item1':[5,4,3,2],\n",
    "        'item2':[4,5,2,3],\n",
    "        'item3':[2,3,5,4]\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data).set_index('user')\n",
    "\n",
    "user_similarity=cosine_similarity(df);\n",
    "print(\"using cosine functions: \",user_similarity);\n",
    "\n",
    "pearson=df.T.corr(method='pearson')\n",
    "\n",
    "print(\"pcc_similarity\",pearson);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b68afc1-1d43-4646-be79-2866a40a8176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user      user1     user2     user3     user4     user5\n",
      "user                                                   \n",
      "user1  1.000000  0.484200 -0.789474 -0.512989 -0.612056\n",
      "user2  0.484200  1.000000 -0.791667 -0.686406  0.476731\n",
      "user3 -0.789474 -0.791667  1.000000  0.359546 -0.238366\n",
      "user4 -0.512989 -0.686406  0.359546  1.000000  0.000000\n",
      "user5 -0.612056  0.476731 -0.238366  0.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "data={\n",
    "    'user':['user1','user2','user3','user4','user5'],\n",
    "    'item1':[5,4,3,2,1],\n",
    "    'item2':[4,5,2,3,6],  \n",
    "    'item3':[2,3,5,4,5],\n",
    "    'item4':[4,3,3,5,2],\n",
    "    'item5':[np.nan,3,5,4,1],\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data).set_index(\"user\")\n",
    "user_similarity=df.T.corr(method=\"pearson\")\n",
    "print(user_similarity)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78222629-8a13-4ff7-867e-87fe58412297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User      User1     User2     User3     User4     user5\n",
      "User                                                   \n",
      "User1  1.000000  0.852803  0.707107  0.000000 -0.792118\n",
      "User2  0.852803  1.000000  0.467707  0.489956 -0.900149\n",
      "User3  0.707107  0.467707  1.000000 -0.161165 -0.466569\n",
      "User4  0.000000  0.489956 -0.161165  1.000000 -0.641503\n",
      "user5 -0.792118 -0.900149 -0.466569 -0.641503  1.000000\n",
      "Recommendations for User1:\n",
      "    Item  Prediction\n",
      "0  Item5    2.254151\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "data = {\n",
    "    'User': ['User1', 'User2', 'User3', 'User4', 'user5'],\n",
    "    'Item1': [5, 3, 4, 3, 1],\n",
    "    'Item2': [3, 1, 3, 3, 5],\n",
    "    'Item3': [4, 2, 4, 1, 5],\n",
    "    'Item4': [4, 3, 3, 5, 2],\n",
    "    'Item5': [np.nan, 3, 5, 4, 1],\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data).set_index('User')\n",
    "user_similarity = df.T.corr(method='pearson')  # Pearson correlation\n",
    "print(user_similarity)\n",
    "\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=df.index, columns=df.index)\n",
    "\n",
    "def predict_rating(user, item):\n",
    "    # Filter out NaN values from the user similarity and item ratings\n",
    "    similarity_scores = user_similarity_df[user]\n",
    "    item_ratings = df[item]\n",
    "\n",
    "    # Only consider non-NaN ratings\n",
    "    mask = ~item_ratings.isna()\n",
    "    similarity_scores = similarity_scores[mask]\n",
    "    item_ratings = item_ratings[mask]\n",
    "\n",
    "    if similarity_scores.empty or item_ratings.empty:\n",
    "        return 0  # Return 0 if no relevant data for prediction\n",
    "\n",
    "    numerator = np.sum(similarity_scores * item_ratings)\n",
    "    denominator = np.sum(np.abs(similarity_scores))\n",
    "\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    return numerator / denominator\n",
    "\n",
    "def recommend_items(user):\n",
    "    unrated_items = df.columns[pd.isna(df.loc[user])]  # Items that the user hasn't rated\n",
    "    predictions = [predict_rating(user, item) for item in unrated_items]\n",
    "    recommendations = pd.DataFrame({'Item': unrated_items, 'Prediction': predictions})\n",
    "    return recommendations.sort_values(by='Prediction', ascending=False)\n",
    "\n",
    "user_to_recommend = 'User1'\n",
    "recommendations = recommend_items(user_to_recommend)\n",
    "print(f\"Recommendations for {user_to_recommend}:\")\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e44f6d4-bc91-464f-984d-4125bd1dec27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User-User Similarity (Mean-Centered, Cosine):\n",
      "User      Alice     User1     User2     User3     User4\n",
      "User                                                   \n",
      "Alice  1.000000  0.790569  0.422577  0.000000 -0.690066\n",
      "User1  0.790569  1.000000  0.467707  0.489956 -0.900149\n",
      "User2  0.422577  0.467707  1.000000 -0.161165 -0.466569\n",
      "User3  0.000000  0.489956 -0.161165  1.000000 -0.641503\n",
      "User4 -0.690066 -0.900149 -0.466569 -0.641503  1.000000\n",
      "\n",
      "Updated DataFrame with Missing Value Filled:\n",
      "       Item1  Item2  Item3  Item4     Item5\n",
      "User                                       \n",
      "Alice      5      3      4      4  4.808999\n",
      "User1      3      1      2      3  3.000000\n",
      "User2      4      3      4      3  5.000000\n",
      "User3      3      3      1      5  4.000000\n",
      "User4      1      5      5      2  1.000000\n"
     ]
    }
   ],
   "source": [
    "n #WITH MEAN CENTRIC COSINE\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define the data\n",
    "data = {\n",
    "    'User': ['Alice', 'User1', 'User2', 'User3', 'User4'],\n",
    "    'Item1': [5, 3, 4, 3, 1],\n",
    "    'Item2': [3, 1, 3, 3, 5],\n",
    "    'Item3': [4, 2, 4, 1, 5],\n",
    "    'Item4': [4, 3, 3, 5, 2],\n",
    "    'Item5': [np.nan, 3, 5, 4, 1],\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data).set_index('User')\n",
    "\n",
    "# Calculate the mean rating for each user, excluding NaN values\n",
    "user_means = df.mean(axis=1)\n",
    "\n",
    "# Mean-center the ratings (subtract each user's mean from their ratings)\n",
    "mean_centered_df = df.sub(user_means, axis=0)\n",
    "\n",
    "# Replace NaN values with 0 for cosine similarity calculation\n",
    "cosine_input = mean_centered_df.fillna(0)\n",
    "\n",
    "# Compute user-user cosine similarity\n",
    "cosine_sim_matrix = cosine_similarity(cosine_input)\n",
    "user_similarity_df = pd.DataFrame(cosine_sim_matrix, index=df.index, columns=df.index)\n",
    "\n",
    "print(\"\\nUser-User Similarity (Mean-Centered, Cosine):\")\n",
    "print(user_similarity_df)\n",
    "\n",
    "# Function to predict missing values using user-based collaborative filtering\n",
    "def predict_missing_value(df, user_similarity_df, target_user, target_item, user_means):\n",
    "    # Check if the target item is actually missing for the target user\n",
    "    if not np.isnan(df.loc[target_user, target_item]):\n",
    "        return df.loc[target_user, target_item]\n",
    "    \n",
    "    # Initialize numerator and denominator\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    \n",
    "    # Iterate over all users\n",
    "    for other_user in df.index:\n",
    "        if other_user == target_user or np.isnan(df.loc[other_user, target_item]):\n",
    "            continue\n",
    "        \n",
    "        # Get similarity and rating of the other user\n",
    "        similarity = user_similarity_df.loc[target_user, other_user]\n",
    "        if similarity > 0:  # Only consider positive similarities\n",
    "            rating = df.loc[other_user, target_item]\n",
    "            \n",
    "            # Accumulate weighted ratings (mean-centered) and similarities\n",
    "            numerator += similarity * (rating - user_means[other_user])\n",
    "            denominator += abs(similarity)\n",
    "    \n",
    "    # Predict the value by adding back the target user's mean\n",
    "    return user_means[target_user] + (numerator / denominator if denominator != 0 else 0)\n",
    "\n",
    "# Predict the missing value for Alice's Item5\n",
    "predicted_value = predict_missing_value(df, user_similarity_df, target_user='Alice', target_item='Item5', user_means=user_means)\n",
    "\n",
    "# Update the DataFrame with the predicted value\n",
    "df.loc['Alice', 'Item5'] = predicted_value\n",
    "\n",
    "# Display updated DataFrame\n",
    "print(\"\\nUpdated DataFrame with Missing Value Filled:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "183a54c7-ca9a-401d-81dd-08f32de67dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities of the dataframe\n",
      "User      Alice     User1     User2     User3     User4\n",
      "User                                                   \n",
      "Alice  1.000000  0.826869  0.810163  0.762770  0.789542\n",
      "User1  0.826869  1.000000  0.959383  0.935693  0.637815\n",
      "User2  0.810163  0.959383  1.000000  0.894427  0.771517\n",
      "User3  0.762770  0.935693  0.894427  1.000000  0.638311\n",
      "User4  0.789542  0.637815  0.771517  0.638311  1.000000\n",
      "\n",
      "Updated DataFrame with Missing Value Filled:\n",
      "       Item1  Item2  Item3  Item4     Item5\n",
      "User                                       \n",
      "Alice      5      3      4      4  3.252093\n",
      "User1      3      1      2      3  3.000000\n",
      "User2      4      3      4      3  5.000000\n",
      "User3      3      3      1      5  4.000000\n",
      "User4      1      5      5      2  1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "data = {\n",
    "    'User': ['Alice', 'User1', 'User2', 'User3', 'User4'],\n",
    "    'Item1': [5, 3, 4, 3, 1],\n",
    "    'Item2': [3, 1, 3, 3, 5],\n",
    "    'Item3': [4, 2, 4, 1, 5],\n",
    "    'Item4': [4, 3, 3, 5, 2],\n",
    "    'Item5': [np.nan, 3, 5, 4, 1],\n",
    "}\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data).set_index('User')\n",
    "cosine_input = df.fillna(0)\n",
    "# Compute user-user similarity using Pearson Correlation\n",
    "cosine_sim_matrix = cosine_similarity(cosine_input)\n",
    "user_similarity_df = pd.DataFrame(cosine_sim_matrix, index=df.index, columns=df.index)\n",
    "\n",
    "print(\"\\nSimilarities of the dataframe\")\n",
    "print(user_similarity_df)\n",
    "\n",
    "\n",
    "# Function to predict missing values using user-based collaborative filtering\n",
    "def predict_missing_value(df, user_similarity_df, target_user, target_item):\n",
    "    # Check if the target item is actually missing for the target user\n",
    "    if not np.isnan(df.loc[target_user, target_item]):\n",
    "        return df.loc[target_user, target_item]\n",
    "    \n",
    "    # Initialize numerator and denominator\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    \n",
    "    # Iterate over all users\n",
    "    for other_user in df.index:\n",
    "        if other_user == target_user or np.isnan(df.loc[other_user, target_item]):\n",
    "            continue\n",
    "        \n",
    "        # Get similarity and rating of the other user\n",
    "        if(user_similarity_df.loc[target_user, other_user]>0):\n",
    "            similarity = user_similarity_df.loc[target_user, other_user]\n",
    "            rating = df.loc[other_user, target_item]\n",
    "            \n",
    "            # Accumulate weighted ratings and similarities\n",
    "            numerator += similarity * rating\n",
    "            denominator += abs(similarity)\n",
    "        \n",
    "        \n",
    "    # Calculate and return predicted value\n",
    "    return numerator / denominator if denominator != 0 else np.nan\n",
    "\n",
    "# Predict the missing value for Alice's Item5\n",
    "predicted_value = predict_missing_value(df, user_similarity_df, target_user='Alice', target_item='Item5')\n",
    "\n",
    "# Update the DataFrame with the predicted value\n",
    "df.loc['Alice', 'Item5'] = predicted_value\n",
    "\n",
    "# Display updated DataFrame\n",
    "print(\"\\nUpdated DataFrame with Missing Value Filled:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f84cf1-7a97-459d-8002-e4301f0906a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr [[4.95348425 2.98879899 3.97631571 1.00014954]\n",
      " [3.97144631 2.41264473 3.2194069  0.99817691]\n",
      " [1.00122875 0.99979729 1.5622703  4.94399989]\n",
      " [4.83309146 2.9690518  3.98107545 1.60972726]]\n"
     ]
    }
   ],
   "source": [
    "#MATRIX FACTORIZATION\n",
    "import numpy\n",
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.01, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - numpy.dot(P[i,:],Q[:,j]) \n",
    "                    for k in range(K): \n",
    "                        P[i][k] = P[i][k] + alpha * (eij * Q[k][j] - beta * P[i][k]) \n",
    "                        Q[k][j] = Q[k][j] + alpha * (eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = numpy.dot (P,Q)\n",
    "    return P, Q.T\n",
    "R = [[5,3,0,1],\n",
    "     [4,0,0,1],\n",
    "     [1,1,0,5],\n",
    "     [0,3,4,0], ]\n",
    "R = numpy.array(R)\n",
    "N = len(R)\n",
    "M = len(R[0])\n",
    "K = 2\n",
    "# P = numpy.random.rand(N,K)\n",
    "# Q = numpy.random.rand(M,K)\n",
    "P=[[0.5,0.8],\n",
    "   [0.3,0.6],\n",
    "   [0.9,0.4],\n",
    "   [0.2,0.7], ]\n",
    "Q=[[0.6,0.2],\n",
    "   [0.1,0.5],\n",
    "   [0.8,0.9],\n",
    "   [0.3,0.4], ]\n",
    "P = numpy.array(P)\n",
    "Q = numpy.array(Q)\n",
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "nR = numpy.dot(nP, nQ.T)\n",
    "print('nr',nR)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7398bed-6589-4212-80c2-8f7abef60322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U [[-0.54160611 -0.46810733]\n",
      " [-0.44886273 -0.34079387]\n",
      " [-0.37893089  0.79651311]\n",
      " [-0.6013289   0.17407452]]\n",
      "S [[11.595673    0.        ]\n",
      " [ 0.          4.53422491]]\n",
      "Vt [[-0.60255783 -0.42514934 -0.52057891 -0.43031348]\n",
      " [-0.50679847 -0.20677625  0.06583749  0.8343047 ]]\n",
      "\n",
      "missing predicted\n",
      "[[5.   3.   3.13 1.  ]\n",
      " [4.   2.53 2.61 1.  ]\n",
      " [1.   1.   2.53 5.  ]\n",
      " [3.8  3.   4.   3.66]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "\n",
    "def svd_impute(data, k=2):\n",
    "    data = np.array(data, dtype=np.float64)\n",
    "    mask = data == 0  # Identify missing values\n",
    "    mean_values = np.mean(data, axis=1, where=~mask, keepdims=True)\n",
    "    # Tile mean_values to match the shape of mask\n",
    "    mean_values = np.tile(mean_values, (1, data.shape[1]))\n",
    "    data[mask] = mean_values[mask]  # Temporary fill with row mean\n",
    "\n",
    "    U, S, Vt = svd(data, full_matrices=False)  # Compute SVD\n",
    "    S = np.diag(S[:k])  # Reduce rank to k\n",
    "    U = U[:, :k]\n",
    "    Vt = Vt[:k, :]\n",
    "    print('U',U)\n",
    "    print('S',S)\n",
    "    print('Vt',Vt)\n",
    "\n",
    "    reconstructed = U @ S @ Vt  # Reconstruct the matrix\n",
    "\n",
    "    data[mask] = reconstructed[mask]  # Replace only missing values\n",
    "    return data\n",
    "\n",
    "data = [\n",
    "    [5, 3, 0, 1],\n",
    "    [4, 0, 0, 1],\n",
    "    [1, 1, 0, 5],\n",
    "    [0, 3, 4, 0],\n",
    "]\n",
    "\n",
    "predicted_ratings = svd_impute(data, k=2)\n",
    "print(\"\\nmissing predicted\")\n",
    "\n",
    "print(np.round(predicted_ratings, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f03e31-257d-40ab-9bf8-a2e9b6a53b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "[[5. 3. 0. 1.]\n",
      " [4. 0. 0. 1.]\n",
      " [1. 1. 0. 5.]\n",
      " [0. 3. 4. 0.]]\n",
      "\n",
      "Predicted Data:\n",
      "[[5.         3.         4.         1.        ]\n",
      " [4.         2.26192246 4.         1.        ]\n",
      " [1.         1.         4.         5.        ]\n",
      " [3.51085025 3.         4.         2.45779723]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Given data matrix\n",
    "data = np.array([\n",
    "    [5, 3, 0, 1],\n",
    "    [4, 0, 0, 1],\n",
    "    [1, 1, 0, 5],\n",
    "    [0, 3, 4, 0],\n",
    "], dtype=float)\n",
    "\n",
    "# Mask to identify missing values (0 represents missing values)\n",
    "mask = data > 0\n",
    "\n",
    "# Fill missing values with the mean of the corresponding column\n",
    "column_means = np.nanmean(np.where(mask, data, np.nan), axis=0)\n",
    "filled_data = np.where(mask, data, column_means)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "n_components = 2  # Number of principal components (adjust as needed)\n",
    "pca = PCA(n_components=n_components)\n",
    "reduced_data = pca.fit_transform(filled_data)\n",
    "\n",
    "# Reconstruct the matrix from the reduced data\n",
    "reconstructed_data = pca.inverse_transform(reduced_data)\n",
    "\n",
    "# Replace missing values with predicted values\n",
    "predicted_data = data.copy()\n",
    "predicted_data[~mask] = reconstructed_data[~mask]\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "print(\"\\nPredicted Data:\")\n",
    "print(predicted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50688ad1-7a7d-4999-9e62-3aaddea53059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
